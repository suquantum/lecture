{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f61fa8-c1f0-4256-b375-fb9d4d9dcad1",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "We are going to review one of the examples of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36022f38-5f65-478e-b69b-6f31c94badf1",
   "metadata": {},
   "source": [
    "# Importing Library\n",
    "The following cell is importing the necessary library. Run each cell to load the input/output.\n",
    "For the basic operation of Jupyter Lab, please refer to the link(https://youtu.be/jZ952vChhuI?t=113)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e76d5ba-9513-4cb5-962b-5528bc61777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4c681-4d90-4e05-8594-a4a16bb4ee18",
   "metadata": {},
   "source": [
    "Here, we imported NumPy and matplotlib libraries. The following are a brief explanation\n",
    "1. NumPy is a library for the Python programming language for numerical analysis. We will import mathematical expressions and operations from this library but make a minimum for this tutorial.\n",
    "2. Matplotlib is a library for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856749c-6652-49e7-8df8-46827c3d58ce",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "Data Science(DS) analyzes the data qualitatively to help decision making, business strategy, prediction, forecasting, or optimizing tasks such as predicting the upcoming market based on customers' data, recognizing customer behavior, etc. DS uses various approaches in mathematics and computer sciences to understand data in-depth. Each methodology has advantages and disadvantages. DS compares different approaches and finds the most suitable one to describe the problem. There are numerous theories, methods, and techniques to analyze the issue, and the DS skill set includes but is not limited to only mathematics.\n",
    "\n",
    "## Task of Data Sciences\n",
    "Data Science(DS) is a data-driven consultant in a broad sense. For DS, the following points are essential to delivering an appropriate solution.\n",
    "\n",
    "1. Business understanding.\n",
    "2. Choosing model/s for analysis.\n",
    "3. Proper data sets for analysis.\n",
    "\n",
    "Each of the previous points has multiple layers to process. In this notebook, we will focus on number 2 with Machine Learning (ML) methodology.\n",
    "\n",
    "## Machine Learning\n",
    "The following table is the current main approaches of Machine Learning(ML) and each of them has its files of strength fields and the brief.\n",
    "\n",
    "| Method | Analysis Type | Example of Use Cases | Requirements for the Algorithm |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Supervised learning | 1. Classification <br> 2. Regression | 1. Classification of images such as \"is this a dog or cat image?\" <br> 2. Forecasting how many people are going to rent a car? | Labeled training data |\n",
    "| Unsupervised learning | 1. Association analysis <br> 2. Dimensionality reduction | 1. Recommendation system which finds similar products for customers <br> 2. Reduce dimensions of data to get more insights. For example, lower the patient's data for explainability form and make a diagnose| Sufficient number of data which represents the phenomenon to analyze |\n",
    "| Reinforcement lerning | Rewarding system | Learning chess | Function that describes the score of the system to get the maximum reward |\n",
    "\n",
    "We are going to discuss Supervised Learning in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db797a-9992-4bd2-9022-919e6fc83732",
   "metadata": {},
   "source": [
    "## The Fundamentals of Machine Learning\n",
    "### Input/s and output/s of machine learning model\n",
    "Let's visit some of the fundamental concepts of data analysis. We are going to explain some of the words with an example with a hands-on program.\n",
    "\n",
    "* Input: The input to the algorithm usually is values or data. For example, customer information, images, sounds, etc.\n",
    "* Output: The output from the algorithm which is values or data. For example, barometers of customer's health, classification of images, text converted from sounds, etc.\n",
    "* Model: Algorithm that inhales input data and output data. For example, it is perceptron which we are going to do hands-on exercise soon.\n",
    "\n",
    "Let's see what is the input/output with the actual example.\n",
    "The following is one of the basic models called \"perceptron\" for Deep-Neural-Network(DNN). DNN is one of the most famous algorithms for Artificial Intelligence. We will not step into the detail of DNN.\n",
    "\n",
    "First, we define the perceptron function that we are going to use. Let's focus on the functionality of the perceptron and not go too much into detail. \n",
    "\n",
    "<img src=\"image/perceptron.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "The previous image is one example of the perceptron function. You can see that the violet circle which is the perceptron inhales three inputs. The input data are $x1$, $x2$, and $x3$. Also, the output data is $y$. The $x1$, $x2$, and $x3$ represent different data such as income, dates, and time. The y is the output such as how much possibility of being rejected for applying for a credit card. The following is the perceptron that we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec4474-1a80-4cb8-b689-d9daea91dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a simple perceptron for this exercise\n",
    "def perceptron(x, w):\n",
    "    z = x[0] * w[0] + x[1] * w[1] + x[2] * w[2] + w[3]\n",
    "    return 1.0 / (1.0 + np.exp(-z))  # Sigmoid activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b5965-715f-4aac-8360-5269ecb90140",
   "metadata": {},
   "source": [
    "The next part is, loading the input data. Please execute the following cell to load the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a79a2d-db9e-412f-9f56-9aa4d11cac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target value\n",
    "target = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5780e4-ced4-4321-ac8a-8eed6706ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input values\n",
    "x1 = 0.1\n",
    "x2 = 0.2\n",
    "x3 = -0.1\n",
    "\n",
    "input_x_values = [x1, x2, x3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e52029-eceb-4165-85d2-85a9c629ed47",
   "metadata": {},
   "source": [
    "The next cell is for loading the weights and bias. The weights and the bias are the parameters that represent which features, which are equivalent to input data, contribute to the output value. Getting the correct weights and biases are the most important part which is called training. We will revisit the concept of training later. Here, we assume the training is done and get the proper weights and bais, which is equivalent to building our model. The value can be loaded with the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d174e-5a2c-43ce-ad9e-aec021860cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "w1 = -1.64\n",
    "w2 = -0.98\n",
    "w3 = 1.31\n",
    "\n",
    "# Load Bias/es\n",
    "b1 = -0.05\n",
    "\n",
    "weight_values = [w1, w2, w3, b1]\n",
    "\n",
    "result = perceptron(input_x_values, weight_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db200061-b4b1-42d8-b025-63752157389b",
   "metadata": {},
   "source": [
    "The following is the output value which is equivalent to the result. Based on the weights and given inputs, we can calculate the probability from the perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96295a28-83cc-4afc-87c1-0c8f074b050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the output\n",
    "print(\"Output value from the given perceptron: \", '{:.5g}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d09e9-4d16-4ff3-8b9e-ec40b8b2c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure\n",
    "x = [result]\n",
    "y = [0]\n",
    "\n",
    "x_t = [target]\n",
    "y_t = [0]\n",
    "\n",
    "plt.plot(x, y, 'o', c=\"blue\")\n",
    "plt.plot(x_t, y_t, 'X', c=\"red\")\n",
    "plt.xlim([0, 1.2])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0f3884-a5ea-456a-a6ea-c6a7ef315f4b",
   "metadata": {},
   "source": [
    "Now, we can see the blue dot and the red dot. The red dot is the target value. The blue dot is the probability with the given $x1$, $x2$, and $x3$ which is $0.36795$ ($\\%36.795%$). Let's change the input data and see how the probability will change. We fix the $x1$ and $x2$ and see what will happen to change only $x3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9338096-9d40-451a-9bd9-9f0164e56062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save previous result\n",
    "pre_result = result\n",
    "\n",
    "# Load input values\n",
    "x1 = 0.1\n",
    "x2 = 0.2\n",
    "x3 = 0.9\n",
    "\n",
    "input_x_values = [x1, x2, x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575512b-15a7-47dc-a446-08fdfefbbf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = perceptron(input_x_values, weight_values)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output value from the given perceptron: \", '{:.5g}'.format(result))\n",
    "print()\n",
    "\n",
    "# Plot figure\n",
    "x_p = [pre_result]\n",
    "y_p = [0]\n",
    "\n",
    "x = [result]\n",
    "y = [0]\n",
    "\n",
    "x_t = [target]\n",
    "y_t = [0]\n",
    "\n",
    "plt.plot(x, y, '*', c='m')\n",
    "plt.plot(x_p, y_p, 'o', c=\"blue\")\n",
    "plt.plot(x_t, y_t, 'X', c=\"red\")\n",
    "plt.xlim([0, 1.2])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11311f07-d072-4225-8e88-0e32a1eea533",
   "metadata": {},
   "source": [
    "Now, we can see the magenta point that the probability goes up to $0.6833$. This means that the difference of $x3$ from $-0.1$ to $0.9$ contributes to the probability of about $30$%. In other words, the $x3$ in this model may play an important role to determine the result. Are you convinced that the $x3$ is the most important feature for the output? Let's do some exercise and analysis. On the next cell, change the $x1$, $x2$, and $x3$ several times and derive the probability. Observe how the output will change. Which feature contributes the most?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1227e5b5-70d8-4126-af80-b116644fef79",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "Change the inputs of $x1$, $x2$, and $x3$ values and run the cell sevearal times. Observe the output changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460fc32-450c-4cfc-a760-caaa408e9de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####\n",
    "### YOUR CODE STARTS HERE ###\n",
    "x1 = None  # Replace \"None\" with an arbitrary number\n",
    "x2 = None  # Replace \"None\" with an arbitrary number\n",
    "x3 = None  # Replace \"None\" with an arbitrary number\n",
    "### YOUR CODE ENDS HERE ###\n",
    "#####\n",
    "\n",
    "\n",
    "input_x_values = [x1, x2, x3]\n",
    "\n",
    "# Simulation for numerical results\n",
    "result = perceptron(input_x_values, weight_values)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output value from the given perceptron: \", '{:.5g}'.format(result))\n",
    "print()\n",
    "\n",
    "\n",
    "# Plot figure\n",
    "x = [result]\n",
    "y = [0]\n",
    "\n",
    "x_t = [target]\n",
    "y_t = [0]\n",
    "\n",
    "plt.plot(x, y, '*', c='b')\n",
    "plt.plot(x_t, y_t, 'X', c=\"red\")\n",
    "plt.xlim([0, 1.2])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba395ae-4e15-4600-b546-d34cc4291f5e",
   "metadata": {},
   "source": [
    "### Weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dab2dc-f97d-4612-8ec2-1a3dd9de973d",
   "metadata": {},
   "source": [
    "Next, we are going to see the weights and biases. The weights and biases are the parameters that need to be tuned to reflect the actual phenomenon. For example, if you operate a prediction on a specific customer, the inputs are fixed but somehow find a way to build the model that outputs the reasonable value. This means we are going to tune the weights and biases. First, we load the input which is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4d00c-7b37-4859-948a-c91a0abbdbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input values\n",
    "x1 = 0.1\n",
    "x2 = 0.2\n",
    "x3 = -0.1\n",
    "\n",
    "input_x_values = [x1, x2, x3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51390bb-3758-4b22-871c-a15fa57ec04a",
   "metadata": {},
   "source": [
    "Next, loading the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca44cce-54e1-4670-9cf6-6a8cd31482ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "w1 = -1.64\n",
    "w2 = -0.98\n",
    "w3 = 1.31\n",
    "\n",
    "# Loading and Bias/es\n",
    "b1 = -0.05\n",
    "\n",
    "weight_values = [w1, w2, w3, b1]\n",
    "\n",
    "# Simulation for numerical results\n",
    "result = perceptron(input_x_values, weight_values)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output value from the given perceptron: \", '{:.5g}'.format(result))\n",
    "\n",
    "\n",
    "# Plot figure\n",
    "x = [result]\n",
    "y = [0]\n",
    "\n",
    "x_t = [target]\n",
    "y_t = [0]\n",
    "\n",
    "plt.plot(x, y, '*', c='gold')\n",
    "plt.plot(x_p, y_p, 'o', c=\"blue\")\n",
    "plt.plot(x_t, y_t, 'X', c=\"red\")\n",
    "plt.xlim([0, 1.2])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a49c1-8e10-4fa5-9179-24bd0fdc1486",
   "metadata": {},
   "source": [
    "Let's load different weights and biases and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10369712-5dbb-43cb-8629-e9efd02a3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save previous result\n",
    "pre_result = result\n",
    "\n",
    "# Load weights\n",
    "w1 = 4.64\n",
    "w2 = 3.98\n",
    "w3 = 2.31\n",
    "\n",
    "# Load and Bias/es\n",
    "b1 = 0.05\n",
    "\n",
    "weight_values = [w1, w2, w3, b1]\n",
    "\n",
    "# Simulation for numerical results\n",
    "result = perceptron(input_x_values, weight_values)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output value from the given perceptron: \", '{:.5g}'.format(result))\n",
    "\n",
    "# Plot figure\n",
    "x_p = [pre_result]\n",
    "y_p = [0]\n",
    "\n",
    "x = [result]\n",
    "y = [0]\n",
    "\n",
    "x_t = [target]\n",
    "y_t = [0]\n",
    "\n",
    "plt.plot(x, y, '*', c='m')\n",
    "plt.plot(x_p, y_p, 'o', c=\"blue\")\n",
    "plt.plot(x_t, y_t, 'X', c=\"red\")\n",
    "plt.xlim([0, 1.2])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6005c-7313-4d8f-be30-b470e61197e5",
   "metadata": {},
   "source": [
    "Do you see even the same input gives different outputs depending on the model? Inputs are fixed so we have to do the proper training to get the model. In other words, we have to find the correct weights and biases, or parameters throw the training. Otherwise, the model will not predict correctly. To get the right model, we have to have correct weights and biases which means the parameter. To get the parameter, we have to have a reasonable amount of good data for training. We will step into more detail to this part on the next example with supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2679fb-cf2a-4bca-b324-f047087d6f61",
   "metadata": {},
   "source": [
    "### Exercise 1.2.\n",
    "Change the weights and bias which is $w1$, $w2$, $w3$, and $b1$ and find the parameters that returns the highest value. This is the same process as manual model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983323c-0308-4da8-a8cc-e46eb5eed680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "### YOUR CODE STARTS HERE ###\n",
    "w1 = None  # Replace \"None\" with an arbitrary number\n",
    "w2 = None  # Replace \"None\" with an arbitrary number\n",
    "w3 = None  # Replace \"None\" with an arbitrary number\n",
    "\n",
    "b1 = None  # Replace \"None\" with an arbitrary number\n",
    "### YOUR CODE ENDS HERE ###\n",
    "#####\n",
    "\n",
    "\n",
    "# Load lists\n",
    "weight_values = [w1, w2, w3, b1]\n",
    "\n",
    "# Simulation for numerical results\n",
    "result = perceptron(input_x_values, weight_values)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output value from the given perceptron: \", '{:.5g}'.format(result))\n",
    "\n",
    "# Plot figure\n",
    "x = [result]\n",
    "y = [0]\n",
    "\n",
    "x_t = [target]\n",
    "y_t = [0]\n",
    "\n",
    "plt.plot(x, y, '*', c='blue')\n",
    "plt.plot(x_t, y_t, 'X', c=\"red\")\n",
    "plt.xlim([0, 1.2])\n",
    "plt.ylim([-0.02, 0.02])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
